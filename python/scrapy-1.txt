windows
在python文件目录下Scripts
%APPDATA%创建pip.ini文件
[global]
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
[install]
trusted-host = https://pypi.tuna.tsinghua.edu.cn  # trusted-host 此参数是为了避免麻烦，否则使用的时候可能会提示不受信任
在环境变量 path 加上Scripts路径C:\Python38\Scripts
conda list 命令检验conda是否安装成功
conda install -c conda-forge scrapy 命令安装scrapy框架
linux
pip install --upgrade pip 命令进行pip版本升级。
pip install --upgrade setuptools 命令进行setuptools 版本升级
pip install scrapy
scrapy startproject shuju
cd shuju
scrapy genspider baidu baidu.com
scrapy crawl baidu（运行爬虫）
采集网IP
1.修改爬虫协议
ROBOTSTXT_OBEY = False
2.修改请求头 去掉注释添加'User-Agent'
DEFAULT_REQUEST_HEADERS = {
  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
  'Accept-Language': 'en',
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'
}
查看类型
print(type(response))然后启动可以查看
class 'scrapy.http.response.html.HtmlResponse（这里是类型）
#设置日志等级
LOG_LEVEL= 'WARNING'
xpath语法
3.提前数据
document.querySelector("#signature")
wts问答页
unity-list-tap(问题类型）
box hover-shine(问题名称)
replyList（问题回答）
span标签内容直接一个/就OK
 ter1=response.xpath("//div[@class='replyList']//text()").extract()
        ter2 = response.xpath("//div[@class='box hover-shine']//a/text()").extract()
        # ter3 = response.xpath("//div[@class='replyList']//a/text()").extract()
        print(ter2,ter1)


006
